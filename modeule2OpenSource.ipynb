{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1f2be1b-1837-47ca-8008-1f3e11370e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import minsearch\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "\n",
    "# Initialize OpenAI client\n",
    "#client = OpenAI(\n",
    "    # Replace with your OpenAI API key#\n",
    "#    api_key=os.environ.get(\"OPENAI_API_KEY\"),)\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "# Initialize minsearch Index\n",
    "index = minsearch.Index(\n",
    "    text_fields=['question', 'text', 'section'],\n",
    "    keyword_fields=['course']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c9ffde5-236e-441e-a8c8-f94616c9e2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#documents = []\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "562ec1c4-a27f-449e-8aee-85b84352705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f:\n",
    "    docs_raw = json.load(f)\n",
    "\n",
    "# Flatten and preprocess documents\n",
    "documents = []\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2821cf-243c-45ba-b518-b6873cbc8762",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_name = \"course-questions\"\n",
    "es_client.indices.create(index=index_name,body =index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ac0cc-8f6c-470f-8294-989ffef0e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name,document =doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73395bf1-6623-4eb0-b10f-327359ec9086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x78203e6fdc00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d162519-6b10-44e0-aa7d-dd4954ef98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "    result = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context += f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c334d5e-6f56-4147-bbb7-072d8d4e7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "415145eb-36fa-4a42-bac9-fe7c22cc183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_query(query):\n",
    "    search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es_client.search(index=\"course-questions\", body=search_query)\n",
    "    \n",
    "    results_doc = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    return results_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5afc7e5d-986f-4334-8317-71f00a30b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 =  \"How do I execute a command in a running docker container?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf80b0ca-3566-47c4-b1ef-868fd373a2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18365/3042410418.py:21: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  response = es_client.search(index=\"course-questions\", body=search_query)\n"
     ]
    }
   ],
   "source": [
    "result = elastic_search_query(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef0fe1b-f2bc-4e81-810a-2f8efc74f8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1513"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(build_prompt(query2,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbd75454-1872-4be1-b926-c2f5505b9818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I debug a docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I debug a docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I debug a docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4927d005-1dc1-43a1-b2a4-334159de28ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m870.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.5.15 tiktoken-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3d5b507c-691f-44bf-b507-5e3f9e494e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5778eb1c-7174-4b48-bdc2-b1053910030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(str(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836a392-0c40-4f65-bf15-164eec56ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how do I run kafka?\"\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search_query(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "\n",
    "rag(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6253a73f-5757-47bc-b352-be4d1e32d936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9839ab7-e72e-4d4f-883b-e59d663f6b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/tmp/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775d7041-4578-4fe3-aa1b-16f9d89484dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          32G   24G  6.4G  79% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm              64M     0   64M   0% /dev/shm\n",
      "/dev/root        29G   24G  5.6G  81% /vscode\n",
      "/dev/loop3       32G   24G  6.4G  79% /workspaces\n",
      "/dev/sdb1        44G  112K   42G   1% /tmp\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50710605-1e28-48af-8b00-0614aa5f46dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          7.7Gi       1.7Gi       2.4Gi        67Mi       3.7Gi       5.7Gi\n",
      "Swap:            0B          0B          0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bdad2ce-7b8b-4247-a607-2e9fff009d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec024f64-7287-49b1-9975-603e208370e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\")\n",
    "\n",
    "input_text = \"translate English to German: How old are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d25b0d-e351-46e5-877e-a44709a4b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\")\n",
    "\n",
    "input_text = \"translate English to German: How old are you?\"\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate output\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccef3a8-00fe-42b0-b6e6-38a0e0cc78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp/cache/hub/models--google--flan-t5-xl/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3181166-7b7b-4065-b937-0d2a9bf282c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd4cb7-a868-43a2-adcb-fdbb81633bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "544fa47e-eb74-4efe-ad5a-a877e394aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"documents.json\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"File downloaded successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429f33f-a395-4af5-925b-971a0d9f8365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
